{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проектная работа 3 Курс 2021/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Идентификация фунции фитнеса методами машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Этап 0 | Постановка задачи | Ожидаемый результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель проекта: Восстановление функции фитнеса, с помощью различных методов машинного обучения\n",
    "\n",
    "План работы:\n",
    "- Теоретический модуль\n",
    "   1. Для начала стоит изучить доступную литературу по данному предмету (список находится в конце Этапа 0)\n",
    "   2. Изучить базовые возможности и синтаксис языка программирования Python\n",
    "   3. Создание и исследование математической модели\n",
    "   4. Ознакомление с возможностями Jupiter Notebook\n",
    "- Практический модуль\n",
    "   1. Создание обучающей выборки\n",
    "   2. Обучение классификаторов\n",
    "   3. Правка багов и аномалий (тестирование и исправление ошибок)\n",
    "   4. Написание финального отчета по окончаю проекта\n",
    "\n",
    "Краткое изложение всей теоретической базы (*За более подробными данными в список литературы*)\n",
    "\n",
    "Функция фитнеса - это функция биологической приспособленности\n",
    "- Благодаря выявлению функции фитнеса есть возможность найти оптимальное решение\n",
    "- Следовательно найти оптимальную стратегию поведения\n",
    "\n",
    "Фитнес всегда определятеся по разному, но по всем (**моим**) наблюдениям это какая-то функция, которая зависит от различных параметров. Эти параметры (*Макропараметры*) в данной проектной работе представляют из себя описание окружающей среды, количество хищников, естественную смертность и тд. (*Более подробно в Этапе 1)\n",
    "\n",
    "> Читатель: Почему объектом изучения является Зоопланктон?\n",
    "\n",
    "> Breketov: Ну потому что это хорошо изученные организмы, + они перемещаются по всеми известной синусоиде (**Ни в коем случае не путать с косинусоидой о которой как оказалось никто не знает**)\n",
    "\n",
    "> Breketov: Кстати говоря их перемещения носят отдельной научное название - суточные вертикальные миграции (СВМ) или на english (DVM - Diel vertical migration)\n",
    "\n",
    "> Breketov: Ну а еще если переводить это в математику, то окажется, что выходит довольно простая система, с большим количесвом эмпирических данных\n",
    "\n",
    "> Читатель: Я понял, можешь больше не продолжать, душнила.\n",
    "\n",
    "> Высший разум: Рыбка плавать вверх и вниз и вкусно получать (Это шутка)\n",
    "\n",
    "Ну и после небольших бед с б**кой можно поговорить об обучающей выборке:\n",
    "- Выборка - конечный отбор чего-то с известной принадлежностью к одному из двух множеств\n",
    "- И в работе необходимо будет создать обучающую выборку, в которой представлены признаки и принадлежность к определенному классу\n",
    "\n",
    "В проектной работе в качестве стратегий будут две синусоиды (**НЕ КОСИНУСОИДЫ**), где одна относится к молодым особям, ну то есть к джунам, а другая к взрослым, ну или к сеньорам. Ну и касаемо ранжирования стоит сказать что в данном случае у нас будут сравниваться i-ый элемент с со всеми j-ими.\n",
    "\n",
    "В проекте мы реализуем 2 главных метода классификации:\n",
    "- Метод опорных векторов или на english мове (SVM)\n",
    "- Фишеровский дискриминант или на мове (LDA)\n",
    "- *Бонусом можно обучить нейронную сеть, но это если будет желание)\n",
    "\n",
    "Ну и в итоге планируется получить как можно более точные и правдоподобные результаты (*по крайней мере чтобы не оказалось так, что хищники увеличили популяцию зооплантончика нашего ненаглядного*)\n",
    "\n",
    "Чорт, чуть не забыл про литературу нашу любимую:\n",
    "\n",
    "- [*Exploring Evolutionary Fitness in Biological Systems Using Machine Learning Methods*](https://www.mdpi.com/1099-4300/23/1/35/htm)\n",
    "- [*Лекции от Вышки по МО*](https://github.com/esokolov/ml-course-hse)\n",
    "- [*Почему только 2, а потому что все легко гуглится мы же в 21 веке живем чувак) Это кстати тоже ссылка можешь перейти*](https://www.youtube.com/watch?v=dQw4w9WgXcQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Этап 1 | Обучающая выборка | Ранжирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Построение обучающей выборки (Теория)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть имеют место параметризации функций окружающей среды:\n",
    "\n",
    "- $E(x)$ - пространственное распределение пищи по вертикальной координате $x$\n",
    "\n",
    "- $S(x)$ - пространственное распределение хищников по вертикальной координате $x$\n",
    "\n",
    "- $S(t)$ - активность хищников\n",
    "\n",
    "- $G(x)$ - совокупность дополнительных факторов окружающей среды, типо перепадов температур, радиция и тд.\n",
    "\n",
    "И нам известны параметры $D$ - максимальная глубина и $D_0$ - оптимальная глубина. А так же $\\sigma_1 = 1$, $\\sigma_2 = 1$\n",
    "$$\n",
    "\\begin{cases}\n",
    "    E = \\sigma_1 (x + D)\\\\\n",
    "    S_x = \\sigma_2 (x + D)\n",
    "\\end{cases}\n",
    "-D < x < 0\n",
    "$$\n",
    "$$\n",
    "\\begin{cases}\n",
    "    G = (x + D_0)^2\\\\\n",
    "    S_{\\tau} = cos(2\\pi\\tau) + 1\n",
    "\\end{cases}\n",
    "0 < \\tau < 1\n",
    "$$\n",
    "Возьмем в качестве $v_i$ стратегии две стадии жизнии зоопланктона: молодых и взрослых особей\n",
    "$$\n",
    "x_{J} = A_{J} + B_{J}cos(2\\pi\\tau)\\ \\ \\ \\ \\ \\ x_{A} = A_{A} + B_{A}cos(2\\pi\\tau)\n",
    "$$\n",
    "\n",
    "Где мы должны ограничения для параметров A и B такие что: $ -D < A < 0$, $|B| < min(A + D, -A)$\n",
    "\n",
    "Ключевыми макропараметрами являются:\n",
    "\n",
    "$ M_1 $ и $ М_5 $ - количество потребляемой пищи в сутки\n",
    "\n",
    "$ M_2 $ и $ М_6 $ - суточная смертность от хищников\n",
    "\n",
    "$ M_3 $ и $ М_7 $ - метаболическая стоимость вертикальной миграции\n",
    "\n",
    "$ M_4 $ и $ М_8 $ - смертность зоопланктона от неблагоприятных условий среды\n",
    "\n",
    "        Для молодых особей:\n",
    "$$\n",
    "M_1(v_i) = \\int_0^1 E(x_{Ji}(\\tau))d\\tau\\ \\ \\ \\ \\ \\ M_2(v_i) = \\int_0^1 S_{\\tau}(\\tau)S_x(x_{Ji}(\\tau))d\\tau\\ \\ \\ \\ \\ \\ M_3(v_i) = -\\int_0^1 (x'_{Ji}(\\tau))^2d\\tau\\ \\ \\ \\ \\ \\ M_4(v_i) = -\\int_0^1 G(x_{Ji}(\\tau))d\\tau\n",
    "$$\n",
    "        Для взрослых особей:\n",
    "$$\n",
    "M_5(v_i) = \\int_0^1 E(x_{Ai}(\\tau))d\\tau\\ \\ \\ \\ \\ \\ M_6(v_i) = \\int_0^1 S_{\\tau}(\\tau)S_x(x_{Ai}(\\tau))d\\tau\\ \\ \\ \\ \\ \\ M_7(v_i) = -\\int_0^1 (x'_{Ai}(\\tau))^2d\\tau\\ \\ \\ \\ \\ \\ M_8(v_i) = -\\int_0^1 G(x_{Ai}(\\tau))d\\tau\n",
    "$$\n",
    "\n",
    "Известная функция фитнеса: $ J = -s-p-q+\\sqrt[2]{4rp+(p+q-s)^2} $\n",
    "\n",
    "С коэффициентами:\n",
    "\n",
    "$ r_i = \\alpha_{A} M_5 + \\beta_{A} M_7 + \\delta_{A} M_8 $\n",
    "\n",
    "\n",
    "$ s_i = \\gamma_{A}M_6 $\n",
    "\n",
    "\n",
    "$ p_i = \\alpha_{J}M_1 + \\beta_{J} M_3 + \\delta_{J} M_4 $\n",
    "\n",
    "\n",
    "$ q_i = \\gamma_{J}M_2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. План действий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Прямой ход работы\n",
    "Мы генериеруем ключевые параметры А и В стратегий $v_i$ для двух стадий зоопланктона: молодых и взрослых особей. \n",
    "\n",
    "Далее мы с помощью А и В уже находим макропараметры $M_1,...,M_8$ и уже зная их мы можем с помощью имеющихся эмпирических данных посчитать значения функции фитнеса для всех стратегий. \n",
    "\n",
    "Следующим шагом нам предстоит воспользоваться сравнением пар получившихся значений фитнеса, чтобы разбить их на два базовых класс и уже эти классы мы предъявим нашему классификатору для непосредственного ранжирования с помощью метода опорных векторов или линейного дискриминанта Фишера "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Программный ход работы\n",
    "\n",
    "Производим генерацию параметров стратегий, далее просчитываем макропараметры для каждой стратегии. Имея это можем найти значения известной функции фитнеса, а следовательно можем разделить на классы и уже непосредственно сформировать обучающую выборку, после ее формирования производим обучение моделей и получаем из этих моделей коэффициенты гиперплоскости, те в свою очередь являются коэффициентами функции фитнеса. На этом пока все, далее будет 2 Этап."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Подготовка всех исходных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эмпирические данные \n",
    "alpha_j = 0.0016\n",
    "alpha_a = 0.006\n",
    "betta_j = 0.0000007\n",
    "betta_a = 0.000000075\n",
    "gamma_j = 0.00008\n",
    "gamma_a = 0.004\n",
    "delta_j = 0.000016\n",
    "delta_a = 0.00006\n",
    "sigma1 = 1\n",
    "sigma2 = 1\n",
    "\n",
    "D = 120\n",
    "D0 = 70  \n",
    "\n",
    "Nmax = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_J</th>\n",
       "      <th>B_J</th>\n",
       "      <th>A_A</th>\n",
       "      <th>B_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-22.3442</td>\n",
       "      <td>7.5117</td>\n",
       "      <td>-27.9471</td>\n",
       "      <td>-3.0107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-24.1080</td>\n",
       "      <td>-7.3936</td>\n",
       "      <td>-64.0493</td>\n",
       "      <td>-29.6122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-62.8407</td>\n",
       "      <td>33.7045</td>\n",
       "      <td>-73.4211</td>\n",
       "      <td>-37.8277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-46.2176</td>\n",
       "      <td>-22.5796</td>\n",
       "      <td>-26.0761</td>\n",
       "      <td>-23.3598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-117.5582</td>\n",
       "      <td>-0.8059</td>\n",
       "      <td>-107.1976</td>\n",
       "      <td>-2.0943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-75.1261</td>\n",
       "      <td>-26.3266</td>\n",
       "      <td>-66.5291</td>\n",
       "      <td>-21.1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-10.6138</td>\n",
       "      <td>-3.6597</td>\n",
       "      <td>-54.8512</td>\n",
       "      <td>29.4303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-35.9241</td>\n",
       "      <td>16.2086</td>\n",
       "      <td>-114.9439</td>\n",
       "      <td>3.0624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-88.8454</td>\n",
       "      <td>13.4394</td>\n",
       "      <td>-119.9582</td>\n",
       "      <td>-0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-49.0425</td>\n",
       "      <td>38.4768</td>\n",
       "      <td>-37.4694</td>\n",
       "      <td>0.6705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-22.8037</td>\n",
       "      <td>19.8337</td>\n",
       "      <td>-118.3702</td>\n",
       "      <td>-0.5247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-77.8034</td>\n",
       "      <td>30.4135</td>\n",
       "      <td>-47.2723</td>\n",
       "      <td>-10.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-73.0501</td>\n",
       "      <td>11.0638</td>\n",
       "      <td>-71.5319</td>\n",
       "      <td>42.7757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-112.0175</td>\n",
       "      <td>6.7927</td>\n",
       "      <td>-44.6574</td>\n",
       "      <td>14.2884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-30.2824</td>\n",
       "      <td>7.8493</td>\n",
       "      <td>-3.8022</td>\n",
       "      <td>2.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-73.4185</td>\n",
       "      <td>-26.0628</td>\n",
       "      <td>-68.9363</td>\n",
       "      <td>8.8480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-29.4738</td>\n",
       "      <td>-14.0092</td>\n",
       "      <td>-14.1634</td>\n",
       "      <td>12.1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-19.0072</td>\n",
       "      <td>10.2573</td>\n",
       "      <td>-24.7076</td>\n",
       "      <td>13.1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-82.1988</td>\n",
       "      <td>18.9589</td>\n",
       "      <td>-49.8101</td>\n",
       "      <td>-6.3275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-53.7394</td>\n",
       "      <td>21.4043</td>\n",
       "      <td>-52.9366</td>\n",
       "      <td>2.1613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-89.7027</td>\n",
       "      <td>-25.4425</td>\n",
       "      <td>-65.5430</td>\n",
       "      <td>21.1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-3.9783</td>\n",
       "      <td>2.7533</td>\n",
       "      <td>-53.9677</td>\n",
       "      <td>10.2079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-19.0882</td>\n",
       "      <td>-0.2199</td>\n",
       "      <td>-14.5978</td>\n",
       "      <td>-3.0558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-66.7614</td>\n",
       "      <td>13.0427</td>\n",
       "      <td>-16.7142</td>\n",
       "      <td>-8.5122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-113.5738</td>\n",
       "      <td>3.8488</td>\n",
       "      <td>-99.4865</td>\n",
       "      <td>14.4551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.9130</td>\n",
       "      <td>0.4469</td>\n",
       "      <td>-23.3966</td>\n",
       "      <td>12.6945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-14.6839</td>\n",
       "      <td>-6.8367</td>\n",
       "      <td>-80.8085</td>\n",
       "      <td>23.2653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-68.3355</td>\n",
       "      <td>-50.8341</td>\n",
       "      <td>-115.7977</td>\n",
       "      <td>4.1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-60.1675</td>\n",
       "      <td>-38.2593</td>\n",
       "      <td>-53.7071</td>\n",
       "      <td>-41.4730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-15.1636</td>\n",
       "      <td>-8.2419</td>\n",
       "      <td>-29.0985</td>\n",
       "      <td>-14.4284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         A_J      B_J       A_A      B_A\n",
       "0   -22.3442   7.5117  -27.9471  -3.0107\n",
       "1   -24.1080  -7.3936  -64.0493 -29.6122\n",
       "2   -62.8407  33.7045  -73.4211 -37.8277\n",
       "3   -46.2176 -22.5796  -26.0761 -23.3598\n",
       "4  -117.5582  -0.8059 -107.1976  -2.0943\n",
       "5   -75.1261 -26.3266  -66.5291 -21.1081\n",
       "6   -10.6138  -3.6597  -54.8512  29.4303\n",
       "7   -35.9241  16.2086 -114.9439   3.0624\n",
       "8   -88.8454  13.4394 -119.9582  -0.0400\n",
       "9   -49.0425  38.4768  -37.4694   0.6705\n",
       "10  -22.8037  19.8337 -118.3702  -0.5247\n",
       "11  -77.8034  30.4135  -47.2723 -10.0029\n",
       "12  -73.0501  11.0638  -71.5319  42.7757\n",
       "13 -112.0175   6.7927  -44.6574  14.2884\n",
       "14  -30.2824   7.8493   -3.8022   2.2644\n",
       "15  -73.4185 -26.0628  -68.9363   8.8480\n",
       "16  -29.4738 -14.0092  -14.1634  12.1484\n",
       "17  -19.0072  10.2573  -24.7076  13.1750\n",
       "18  -82.1988  18.9589  -49.8101  -6.3275\n",
       "19  -53.7394  21.4043  -52.9366   2.1613\n",
       "20  -89.7027 -25.4425  -65.5430  21.1192\n",
       "21   -3.9783   2.7533  -53.9677  10.2079\n",
       "22  -19.0882  -0.2199  -14.5978  -3.0558\n",
       "23  -66.7614  13.0427  -16.7142  -8.5122\n",
       "24 -113.5738   3.8488  -99.4865  14.4551\n",
       "25   -1.9130   0.4469  -23.3966  12.6945\n",
       "26  -14.6839  -6.8367  -80.8085  23.2653\n",
       "27  -68.3355 -50.8341 -115.7977   4.1373\n",
       "28  -60.1675 -38.2593  -53.7071 -41.4730\n",
       "29  -15.1636  -8.2419  -29.0985 -14.4284"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random as rn\n",
    "import pandas as pd\n",
    "# Генерация параметров для стратегий\n",
    "# Запись параметров  \n",
    "def rand_AB(Nmax):\n",
    "   A_j, B_j, A_a, B_a = [], [], [], []\n",
    "   for i in range(0, Nmax):\n",
    "      Aj = round(rn.uniform(-D, 0), 4)\n",
    "      Bj = round(rn.uniform(-min(Aj + D, -Aj), min(Aj + D, -Aj)), 4)\n",
    "      A_j.append(Aj)\n",
    "      B_j.append(Bj)\n",
    "\n",
    "      Aa = round(rn.uniform(-D, 0), 4)\n",
    "      Ba = round(rn.uniform(-min(Aa + D, -Aa), min(Aa + D, -Aa)), 4)\n",
    "      A_a.append(Aa)\n",
    "      B_a.append(Ba)\n",
    "   data_strat = {'A_J': A_j, 'B_J': B_j, 'A_A': A_a, 'B_A': B_a}\n",
    "   data = pd.DataFrame(data = data_strat)\n",
    "   data.to_csv(\"data_strat.csv\", index=False)\n",
    "   return data\n",
    "data_strat = rand_AB(Nmax)\n",
    "data_strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "# Нормализуем макропараметры для увеличения скорости классификатора\n",
    "def macro_norm(collect, collect_M, collect_MM):\n",
    "   M1 = defaultdict(list)\n",
    "   M2 = defaultdict(list)\n",
    "   M3 = defaultdict(list)\n",
    "   for i in range(1, 9):\n",
    "      Z = list(np.array(collect['M' + str(i)])/max(np.abs(collect['M' + str(i)])))\n",
    "      M1['M' + str(i) + '_n'].append(Z)\n",
    "   for i in range(1, 9):\n",
    "      for j in range(1, 9):\n",
    "         if i == j:\n",
    "            Z = np.array(collect_M['M' + str(i) + 'M' + str(j)])/max(np.abs(collect_M['M' + str(i) + 'M' + str(j)])[0])\n",
    "            M2['M' + str(i) + 'M' + str(j) + '_n'].append(list(Z[0]))\n",
    "         else:\n",
    "            continue   \n",
    "   for i in range(2, 9):\n",
    "      for j in range(1, i):\n",
    "         Z = np.array(collect_MM['M' + str(i) + 'M' + str(j)])/max(np.abs(collect_MM['M' + str(i) + 'M' + str(j)])[0])\n",
    "         M3['M' + str(i) + 'M' + str(j) + '_n'].append(list(Z[0]))\n",
    "   return M1, M2, M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M1M1</th>\n",
       "      <th>M2M2</th>\n",
       "      <th>...</th>\n",
       "      <th>M7M4</th>\n",
       "      <th>M7M5</th>\n",
       "      <th>M7M6</th>\n",
       "      <th>M8M1</th>\n",
       "      <th>M8M2</th>\n",
       "      <th>M8M3</th>\n",
       "      <th>M8M4</th>\n",
       "      <th>M8M5</th>\n",
       "      <th>M8M6</th>\n",
       "      <th>M8M7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.826982</td>\n",
       "      <td>-0.857166</td>\n",
       "      <td>-0.021836</td>\n",
       "      <td>-0.495970</td>\n",
       "      <td>0.792209</td>\n",
       "      <td>-0.771734</td>\n",
       "      <td>-4.953826e-03</td>\n",
       "      <td>-0.404355</td>\n",
       "      <td>0.683899</td>\n",
       "      <td>0.734733</td>\n",
       "      <td>...</td>\n",
       "      <td>6.809952e-03</td>\n",
       "      <td>-7.317699e-03</td>\n",
       "      <td>6.421168e-03</td>\n",
       "      <td>-0.440132</td>\n",
       "      <td>0.437903</td>\n",
       "      <td>0.018383</td>\n",
       "      <td>0.390394</td>\n",
       "      <td>-0.320333</td>\n",
       "      <td>0.312054</td>\n",
       "      <td>0.008302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.812045</td>\n",
       "      <td>-0.779265</td>\n",
       "      <td>-0.021154</td>\n",
       "      <td>-0.460189</td>\n",
       "      <td>0.481513</td>\n",
       "      <td>-0.350674</td>\n",
       "      <td>-4.792334e-01</td>\n",
       "      <td>-0.108069</td>\n",
       "      <td>0.659418</td>\n",
       "      <td>0.607254</td>\n",
       "      <td>...</td>\n",
       "      <td>6.112671e-01</td>\n",
       "      <td>-4.302778e-01</td>\n",
       "      <td>2.822647e-01</td>\n",
       "      <td>-0.115506</td>\n",
       "      <td>0.106399</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>0.096811</td>\n",
       "      <td>-0.052037</td>\n",
       "      <td>0.037897</td>\n",
       "      <td>0.214645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.484044</td>\n",
       "      <td>-0.625571</td>\n",
       "      <td>-0.439608</td>\n",
       "      <td>-0.133576</td>\n",
       "      <td>0.400859</td>\n",
       "      <td>-0.235788</td>\n",
       "      <td>-7.820340e-01</td>\n",
       "      <td>-0.165842</td>\n",
       "      <td>0.234299</td>\n",
       "      <td>0.391339</td>\n",
       "      <td>...</td>\n",
       "      <td>2.895364e-01</td>\n",
       "      <td>-5.845359e-01</td>\n",
       "      <td>3.097089e-01</td>\n",
       "      <td>-0.105659</td>\n",
       "      <td>0.131076</td>\n",
       "      <td>0.151791</td>\n",
       "      <td>0.043123</td>\n",
       "      <td>-0.066479</td>\n",
       "      <td>0.039104</td>\n",
       "      <td>0.537520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.624814</td>\n",
       "      <td>-0.528209</td>\n",
       "      <td>-0.197298</td>\n",
       "      <td>-0.176991</td>\n",
       "      <td>0.808310</td>\n",
       "      <td>-0.700963</td>\n",
       "      <td>-2.982250e-01</td>\n",
       "      <td>-0.502233</td>\n",
       "      <td>0.390392</td>\n",
       "      <td>0.279004</td>\n",
       "      <td>...</td>\n",
       "      <td>1.462999e-01</td>\n",
       "      <td>-4.494863e-01</td>\n",
       "      <td>3.511113e-01</td>\n",
       "      <td>-0.413029</td>\n",
       "      <td>0.335168</td>\n",
       "      <td>0.206307</td>\n",
       "      <td>0.173039</td>\n",
       "      <td>-0.405961</td>\n",
       "      <td>0.352047</td>\n",
       "      <td>0.620758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020678</td>\n",
       "      <td>-0.017233</td>\n",
       "      <td>-0.000251</td>\n",
       "      <td>-0.487950</td>\n",
       "      <td>0.110178</td>\n",
       "      <td>-0.100190</td>\n",
       "      <td>-2.397086e-03</td>\n",
       "      <td>-0.316065</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>...</td>\n",
       "      <td>3.241952e-03</td>\n",
       "      <td>-4.924603e-04</td>\n",
       "      <td>4.033778e-04</td>\n",
       "      <td>-0.008602</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.300219</td>\n",
       "      <td>-0.034823</td>\n",
       "      <td>0.031666</td>\n",
       "      <td>0.003140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.380007</td>\n",
       "      <td>-0.268029</td>\n",
       "      <td>-0.268213</td>\n",
       "      <td>-0.080420</td>\n",
       "      <td>0.460171</td>\n",
       "      <td>-0.365779</td>\n",
       "      <td>-2.435028e-01</td>\n",
       "      <td>-0.053555</td>\n",
       "      <td>0.144405</td>\n",
       "      <td>0.071839</td>\n",
       "      <td>...</td>\n",
       "      <td>5.427693e-02</td>\n",
       "      <td>-2.089382e-01</td>\n",
       "      <td>1.495989e-01</td>\n",
       "      <td>-0.026786</td>\n",
       "      <td>0.018136</td>\n",
       "      <td>0.029906</td>\n",
       "      <td>0.008384</td>\n",
       "      <td>-0.024644</td>\n",
       "      <td>0.019589</td>\n",
       "      <td>0.054048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.926319</td>\n",
       "      <td>-0.909103</td>\n",
       "      <td>-0.005183</td>\n",
       "      <td>-0.762179</td>\n",
       "      <td>0.560672</td>\n",
       "      <td>-0.680678</td>\n",
       "      <td>-4.733639e-01</td>\n",
       "      <td>-0.151106</td>\n",
       "      <td>0.858066</td>\n",
       "      <td>0.826468</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-4.948777e-01</td>\n",
       "      <td>5.411810e-01</td>\n",
       "      <td>-0.184233</td>\n",
       "      <td>0.173559</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.224195</td>\n",
       "      <td>-0.084721</td>\n",
       "      <td>0.102855</td>\n",
       "      <td>0.296449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.711983</td>\n",
       "      <td>-0.779138</td>\n",
       "      <td>-0.101667</td>\n",
       "      <td>-0.278806</td>\n",
       "      <td>0.043513</td>\n",
       "      <td>-0.056143</td>\n",
       "      <td>-5.125421e-03</td>\n",
       "      <td>-0.461751</td>\n",
       "      <td>0.506919</td>\n",
       "      <td>0.607056</td>\n",
       "      <td>...</td>\n",
       "      <td>3.960763e-03</td>\n",
       "      <td>-4.158547e-04</td>\n",
       "      <td>4.833187e-04</td>\n",
       "      <td>-0.432714</td>\n",
       "      <td>0.454541</td>\n",
       "      <td>0.097740</td>\n",
       "      <td>0.250608</td>\n",
       "      <td>-0.020092</td>\n",
       "      <td>0.025924</td>\n",
       "      <td>0.009809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.263828</td>\n",
       "      <td>-0.320126</td>\n",
       "      <td>-0.069896</td>\n",
       "      <td>-0.096088</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>-0.000186</td>\n",
       "      <td>-8.744314e-07</td>\n",
       "      <td>-0.569210</td>\n",
       "      <td>0.069605</td>\n",
       "      <td>0.102481</td>\n",
       "      <td>...</td>\n",
       "      <td>2.328854e-07</td>\n",
       "      <td>-5.865410e-10</td>\n",
       "      <td>2.728845e-10</td>\n",
       "      <td>-0.197659</td>\n",
       "      <td>0.230221</td>\n",
       "      <td>0.082834</td>\n",
       "      <td>0.106470</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.600892</td>\n",
       "      <td>-0.762366</td>\n",
       "      <td>-0.572912</td>\n",
       "      <td>-0.254414</td>\n",
       "      <td>0.710260</td>\n",
       "      <td>-0.706263</td>\n",
       "      <td>-2.456990e-04</td>\n",
       "      <td>-0.241399</td>\n",
       "      <td>0.361071</td>\n",
       "      <td>0.581202</td>\n",
       "      <td>...</td>\n",
       "      <td>1.732576e-04</td>\n",
       "      <td>-3.253978e-04</td>\n",
       "      <td>2.914577e-04</td>\n",
       "      <td>-0.190922</td>\n",
       "      <td>0.232515</td>\n",
       "      <td>0.287944</td>\n",
       "      <td>0.119553</td>\n",
       "      <td>-0.171456</td>\n",
       "      <td>0.170491</td>\n",
       "      <td>0.000246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.823091</td>\n",
       "      <td>-0.905357</td>\n",
       "      <td>-0.152229</td>\n",
       "      <td>-0.522910</td>\n",
       "      <td>0.014026</td>\n",
       "      <td>-0.011655</td>\n",
       "      <td>-1.504624e-04</td>\n",
       "      <td>-0.533630</td>\n",
       "      <td>0.677478</td>\n",
       "      <td>0.819671</td>\n",
       "      <td>...</td>\n",
       "      <td>2.180733e-04</td>\n",
       "      <td>-3.935125e-06</td>\n",
       "      <td>2.945343e-06</td>\n",
       "      <td>-0.578112</td>\n",
       "      <td>0.610395</td>\n",
       "      <td>0.169131</td>\n",
       "      <td>0.543191</td>\n",
       "      <td>-0.007485</td>\n",
       "      <td>0.006219</td>\n",
       "      <td>0.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.357335</td>\n",
       "      <td>-0.485193</td>\n",
       "      <td>-0.357950</td>\n",
       "      <td>-0.112897</td>\n",
       "      <td>0.625896</td>\n",
       "      <td>-0.577229</td>\n",
       "      <td>-5.468366e-02</td>\n",
       "      <td>-0.129217</td>\n",
       "      <td>0.127688</td>\n",
       "      <td>0.235412</td>\n",
       "      <td>...</td>\n",
       "      <td>1.711148e-02</td>\n",
       "      <td>-6.381956e-02</td>\n",
       "      <td>5.301652e-02</td>\n",
       "      <td>-0.060774</td>\n",
       "      <td>0.079211</td>\n",
       "      <td>0.096300</td>\n",
       "      <td>0.028398</td>\n",
       "      <td>-0.080876</td>\n",
       "      <td>0.074587</td>\n",
       "      <td>0.029285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.397587</td>\n",
       "      <td>-0.443594</td>\n",
       "      <td>-0.047369</td>\n",
       "      <td>-0.015209</td>\n",
       "      <td>0.417117</td>\n",
       "      <td>-0.595380</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-0.209187</td>\n",
       "      <td>0.158076</td>\n",
       "      <td>0.196776</td>\n",
       "      <td>...</td>\n",
       "      <td>4.215429e-02</td>\n",
       "      <td>-7.777720e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.109469</td>\n",
       "      <td>0.117239</td>\n",
       "      <td>0.020631</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>-0.087256</td>\n",
       "      <td>0.124546</td>\n",
       "      <td>0.866979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.067598</td>\n",
       "      <td>-0.096178</td>\n",
       "      <td>-0.017856</td>\n",
       "      <td>-0.385799</td>\n",
       "      <td>0.648400</td>\n",
       "      <td>-0.703032</td>\n",
       "      <td>-1.115766e-01</td>\n",
       "      <td>-0.169755</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>...</td>\n",
       "      <td>1.193113e-01</td>\n",
       "      <td>-1.348994e-01</td>\n",
       "      <td>1.317510e-01</td>\n",
       "      <td>-0.015104</td>\n",
       "      <td>0.020628</td>\n",
       "      <td>0.006311</td>\n",
       "      <td>0.127488</td>\n",
       "      <td>-0.110069</td>\n",
       "      <td>0.119343</td>\n",
       "      <td>0.078500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.759758</td>\n",
       "      <td>-0.791496</td>\n",
       "      <td>-0.023842</td>\n",
       "      <td>-0.346919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-2.802283e-03</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.577233</td>\n",
       "      <td>0.626466</td>\n",
       "      <td>...</td>\n",
       "      <td>2.694556e-03</td>\n",
       "      <td>-5.225240e-03</td>\n",
       "      <td>4.706713e-03</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049641</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.394468</td>\n",
       "      <td>-0.283577</td>\n",
       "      <td>-0.262864</td>\n",
       "      <td>-0.075782</td>\n",
       "      <td>0.439455</td>\n",
       "      <td>-0.472920</td>\n",
       "      <td>-4.278544e-02</td>\n",
       "      <td>-0.009185</td>\n",
       "      <td>0.155605</td>\n",
       "      <td>0.080416</td>\n",
       "      <td>...</td>\n",
       "      <td>8.986900e-03</td>\n",
       "      <td>-3.505941e-02</td>\n",
       "      <td>3.398516e-02</td>\n",
       "      <td>-0.004769</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>0.005027</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>-0.004037</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>0.001629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.766606</td>\n",
       "      <td>-0.705953</td>\n",
       "      <td>-0.075948</td>\n",
       "      <td>-0.375437</td>\n",
       "      <td>0.910831</td>\n",
       "      <td>-0.953812</td>\n",
       "      <td>-8.065734e-02</td>\n",
       "      <td>-0.727874</td>\n",
       "      <td>0.587685</td>\n",
       "      <td>0.498369</td>\n",
       "      <td>...</td>\n",
       "      <td>8.393214e-02</td>\n",
       "      <td>-1.369860e-01</td>\n",
       "      <td>1.292149e-01</td>\n",
       "      <td>-0.734434</td>\n",
       "      <td>0.649207</td>\n",
       "      <td>0.115095</td>\n",
       "      <td>0.531959</td>\n",
       "      <td>-0.662970</td>\n",
       "      <td>0.694255</td>\n",
       "      <td>0.243317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.855241</td>\n",
       "      <td>-0.896974</td>\n",
       "      <td>-0.040715</td>\n",
       "      <td>-0.572240</td>\n",
       "      <td>0.820088</td>\n",
       "      <td>-0.868319</td>\n",
       "      <td>-9.486522e-02</td>\n",
       "      <td>-0.487647</td>\n",
       "      <td>0.731437</td>\n",
       "      <td>0.804563</td>\n",
       "      <td>...</td>\n",
       "      <td>1.504642e-01</td>\n",
       "      <td>-1.450646e-01</td>\n",
       "      <td>1.383541e-01</td>\n",
       "      <td>-0.548932</td>\n",
       "      <td>0.552633</td>\n",
       "      <td>0.041338</td>\n",
       "      <td>0.543212</td>\n",
       "      <td>-0.399913</td>\n",
       "      <td>0.423433</td>\n",
       "      <td>0.191728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.320113</td>\n",
       "      <td>-0.399632</td>\n",
       "      <td>-0.139096</td>\n",
       "      <td>-0.070866</td>\n",
       "      <td>0.604055</td>\n",
       "      <td>-0.571262</td>\n",
       "      <td>-2.188115e-02</td>\n",
       "      <td>-0.097532</td>\n",
       "      <td>0.102472</td>\n",
       "      <td>0.159706</td>\n",
       "      <td>...</td>\n",
       "      <td>4.297896e-03</td>\n",
       "      <td>-2.464569e-02</td>\n",
       "      <td>2.099476e-02</td>\n",
       "      <td>-0.041094</td>\n",
       "      <td>0.049245</td>\n",
       "      <td>0.028246</td>\n",
       "      <td>0.013455</td>\n",
       "      <td>-0.058915</td>\n",
       "      <td>0.055716</td>\n",
       "      <td>0.008845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.561117</td>\n",
       "      <td>-0.650515</td>\n",
       "      <td>-0.177293</td>\n",
       "      <td>-0.106446</td>\n",
       "      <td>0.577149</td>\n",
       "      <td>-0.580790</td>\n",
       "      <td>-2.552912e-03</td>\n",
       "      <td>-0.066936</td>\n",
       "      <td>0.314852</td>\n",
       "      <td>0.423170</td>\n",
       "      <td>...</td>\n",
       "      <td>7.532074e-04</td>\n",
       "      <td>-2.747374e-03</td>\n",
       "      <td>2.490350e-03</td>\n",
       "      <td>-0.049435</td>\n",
       "      <td>0.055013</td>\n",
       "      <td>0.024708</td>\n",
       "      <td>0.013870</td>\n",
       "      <td>-0.038632</td>\n",
       "      <td>0.038876</td>\n",
       "      <td>0.000708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.256568</td>\n",
       "      <td>-0.148559</td>\n",
       "      <td>-0.250501</td>\n",
       "      <td>-0.153552</td>\n",
       "      <td>0.468658</td>\n",
       "      <td>-0.554134</td>\n",
       "      <td>-2.437590e-01</td>\n",
       "      <td>-0.055391</td>\n",
       "      <td>0.065827</td>\n",
       "      <td>0.022070</td>\n",
       "      <td>...</td>\n",
       "      <td>1.037441e-01</td>\n",
       "      <td>-2.130153e-01</td>\n",
       "      <td>2.268723e-01</td>\n",
       "      <td>-0.018705</td>\n",
       "      <td>0.010397</td>\n",
       "      <td>0.028889</td>\n",
       "      <td>0.016557</td>\n",
       "      <td>-0.025960</td>\n",
       "      <td>0.030694</td>\n",
       "      <td>0.055960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.982510</td>\n",
       "      <td>-0.992291</td>\n",
       "      <td>-0.002934</td>\n",
       "      <td>-0.941051</td>\n",
       "      <td>0.568275</td>\n",
       "      <td>-0.606292</td>\n",
       "      <td>-5.694801e-02</td>\n",
       "      <td>-0.070503</td>\n",
       "      <td>0.965327</td>\n",
       "      <td>0.984641</td>\n",
       "      <td>...</td>\n",
       "      <td>1.485386e-01</td>\n",
       "      <td>-6.034361e-02</td>\n",
       "      <td>5.799174e-02</td>\n",
       "      <td>-0.091174</td>\n",
       "      <td>0.088389</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.129153</td>\n",
       "      <td>-0.040065</td>\n",
       "      <td>0.042745</td>\n",
       "      <td>0.016640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.854555</td>\n",
       "      <td>-0.852011</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.559118</td>\n",
       "      <td>0.907093</td>\n",
       "      <td>-0.885317</td>\n",
       "      <td>-5.103353e-03</td>\n",
       "      <td>-0.701089</td>\n",
       "      <td>0.730264</td>\n",
       "      <td>0.725923</td>\n",
       "      <td>...</td>\n",
       "      <td>7.908725e-03</td>\n",
       "      <td>-8.631805e-03</td>\n",
       "      <td>7.588576e-03</td>\n",
       "      <td>-0.788565</td>\n",
       "      <td>0.754692</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.763065</td>\n",
       "      <td>-0.635953</td>\n",
       "      <td>0.620686</td>\n",
       "      <td>0.014829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.450842</td>\n",
       "      <td>-0.505111</td>\n",
       "      <td>-0.065830</td>\n",
       "      <td>-0.020610</td>\n",
       "      <td>0.888879</td>\n",
       "      <td>-0.844027</td>\n",
       "      <td>-3.959947e-02</td>\n",
       "      <td>-0.655825</td>\n",
       "      <td>0.203259</td>\n",
       "      <td>0.255137</td>\n",
       "      <td>...</td>\n",
       "      <td>2.262066e-03</td>\n",
       "      <td>-6.563362e-02</td>\n",
       "      <td>5.613729e-02</td>\n",
       "      <td>-0.389168</td>\n",
       "      <td>0.418530</td>\n",
       "      <td>0.089887</td>\n",
       "      <td>0.026311</td>\n",
       "      <td>-0.582949</td>\n",
       "      <td>0.553534</td>\n",
       "      <td>0.107634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.054419</td>\n",
       "      <td>-0.070582</td>\n",
       "      <td>-0.005732</td>\n",
       "      <td>-0.411153</td>\n",
       "      <td>0.176539</td>\n",
       "      <td>-0.236436</td>\n",
       "      <td>-1.141952e-01</td>\n",
       "      <td>-0.222119</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>...</td>\n",
       "      <td>1.301366e-01</td>\n",
       "      <td>-3.759101e-02</td>\n",
       "      <td>4.534897e-02</td>\n",
       "      <td>-0.015910</td>\n",
       "      <td>0.019808</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.177777</td>\n",
       "      <td>-0.039213</td>\n",
       "      <td>0.052517</td>\n",
       "      <td>0.105125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.831370</td>\n",
       "      <td>-0.877445</td>\n",
       "      <td>-8.807182e-02</td>\n",
       "      <td>-0.513706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.441095e-01</td>\n",
       "      <td>-1.365292e-01</td>\n",
       "      <td>1.297964e-01</td>\n",
       "      <td>-0.676144</td>\n",
       "      <td>0.649031</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.427080</td>\n",
       "      <td>0.450749</td>\n",
       "      <td>0.187510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.891852</td>\n",
       "      <td>-0.861274</td>\n",
       "      <td>-0.018088</td>\n",
       "      <td>-0.665074</td>\n",
       "      <td>0.337283</td>\n",
       "      <td>-0.433173</td>\n",
       "      <td>-2.958170e-01</td>\n",
       "      <td>-0.088366</td>\n",
       "      <td>0.795400</td>\n",
       "      <td>0.741793</td>\n",
       "      <td>...</td>\n",
       "      <td>5.453063e-01</td>\n",
       "      <td>-1.860421e-01</td>\n",
       "      <td>2.152235e-01</td>\n",
       "      <td>-0.103730</td>\n",
       "      <td>0.096157</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.114404</td>\n",
       "      <td>-0.029804</td>\n",
       "      <td>0.038278</td>\n",
       "      <td>0.108338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.437512</td>\n",
       "      <td>-0.221852</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.279301</td>\n",
       "      <td>0.036165</td>\n",
       "      <td>-0.053447</td>\n",
       "      <td>-9.354913e-03</td>\n",
       "      <td>-0.480302</td>\n",
       "      <td>0.191417</td>\n",
       "      <td>0.049218</td>\n",
       "      <td>...</td>\n",
       "      <td>7.242029e-03</td>\n",
       "      <td>-6.308457e-04</td>\n",
       "      <td>8.397881e-04</td>\n",
       "      <td>-0.276585</td>\n",
       "      <td>0.134626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.261140</td>\n",
       "      <td>-0.017370</td>\n",
       "      <td>0.025671</td>\n",
       "      <td>0.018622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.506682</td>\n",
       "      <td>-0.344034</td>\n",
       "      <td>-0.566453</td>\n",
       "      <td>-0.178726</td>\n",
       "      <td>0.570518</td>\n",
       "      <td>-0.388276</td>\n",
       "      <td>-9.400190e-01</td>\n",
       "      <td>-0.256679</td>\n",
       "      <td>0.256726</td>\n",
       "      <td>0.118360</td>\n",
       "      <td>...</td>\n",
       "      <td>4.656646e-01</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>6.130313e-01</td>\n",
       "      <td>-0.171179</td>\n",
       "      <td>0.111569</td>\n",
       "      <td>0.302719</td>\n",
       "      <td>0.089303</td>\n",
       "      <td>-0.146440</td>\n",
       "      <td>0.099662</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.887790</td>\n",
       "      <td>-0.851281</td>\n",
       "      <td>-0.026287</td>\n",
       "      <td>-0.655961</td>\n",
       "      <td>0.782300</td>\n",
       "      <td>-0.713264</td>\n",
       "      <td>-1.137738e-01</td>\n",
       "      <td>-0.405277</td>\n",
       "      <td>0.788170</td>\n",
       "      <td>0.724680</td>\n",
       "      <td>...</td>\n",
       "      <td>2.068558e-01</td>\n",
       "      <td>-1.659623e-01</td>\n",
       "      <td>1.363008e-01</td>\n",
       "      <td>-0.473572</td>\n",
       "      <td>0.435889</td>\n",
       "      <td>0.022181</td>\n",
       "      <td>0.517506</td>\n",
       "      <td>-0.317048</td>\n",
       "      <td>0.289069</td>\n",
       "      <td>0.191103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          M1        M2        M3        M4        M5        M6            M7  \\\n",
       "0   0.826982 -0.857166 -0.021836 -0.495970  0.792209 -0.771734 -4.953826e-03   \n",
       "1   0.812045 -0.779265 -0.021154 -0.460189  0.481513 -0.350674 -4.792334e-01   \n",
       "2   0.484044 -0.625571 -0.439608 -0.133576  0.400859 -0.235788 -7.820340e-01   \n",
       "3   0.624814 -0.528209 -0.197298 -0.176991  0.808310 -0.700963 -2.982250e-01   \n",
       "4   0.020678 -0.017233 -0.000251 -0.487950  0.110178 -0.100190 -2.397086e-03   \n",
       "5   0.380007 -0.268029 -0.268213 -0.080420  0.460171 -0.365779 -2.435028e-01   \n",
       "6   0.926319 -0.909103 -0.005183 -0.762179  0.560672 -0.680678 -4.733639e-01   \n",
       "7   0.711983 -0.779138 -0.101667 -0.278806  0.043513 -0.056143 -5.125421e-03   \n",
       "8   0.263828 -0.320126 -0.069896 -0.096088  0.000360 -0.000186 -8.744314e-07   \n",
       "9   0.600892 -0.762366 -0.572912 -0.254414  0.710260 -0.706263 -2.456990e-04   \n",
       "10  0.823091 -0.905357 -0.152229 -0.522910  0.014026 -0.011655 -1.504624e-04   \n",
       "11  0.357335 -0.485193 -0.357950 -0.112897  0.625896 -0.577229 -5.468366e-02   \n",
       "12  0.397587 -0.443594 -0.047369 -0.015209  0.417117 -0.595380 -1.000000e+00   \n",
       "13  0.067598 -0.096178 -0.017856 -0.385799  0.648400 -0.703032 -1.115766e-01   \n",
       "14  0.759758 -0.791496 -0.023842 -0.346919  1.000000 -1.000000 -2.802283e-03   \n",
       "15  0.394468 -0.283577 -0.262864 -0.075782  0.439455 -0.472920 -4.278544e-02   \n",
       "16  0.766606 -0.705953 -0.075948 -0.375437  0.910831 -0.953812 -8.065734e-02   \n",
       "17  0.855241 -0.896974 -0.040715 -0.572240  0.820088 -0.868319 -9.486522e-02   \n",
       "18  0.320113 -0.399632 -0.139096 -0.070866  0.604055 -0.571262 -2.188115e-02   \n",
       "19  0.561117 -0.650515 -0.177293 -0.106446  0.577149 -0.580790 -2.552912e-03   \n",
       "20  0.256568 -0.148559 -0.250501 -0.153552  0.468658 -0.554134 -2.437590e-01   \n",
       "21  0.982510 -0.992291 -0.002934 -0.941051  0.568275 -0.606292 -5.694801e-02   \n",
       "22  0.854555 -0.852011 -0.000019 -0.559118  0.907093 -0.885317 -5.103353e-03   \n",
       "23  0.450842 -0.505111 -0.065830 -0.020610  0.888879 -0.844027 -3.959947e-02   \n",
       "24  0.054419 -0.070582 -0.005732 -0.411153  0.176539 -0.236436 -1.141952e-01   \n",
       "25  1.000000 -1.000000 -0.000077 -1.000000  0.831370 -0.877445 -8.807182e-02   \n",
       "26  0.891852 -0.861274 -0.018088 -0.665074  0.337283 -0.433173 -2.958170e-01   \n",
       "27  0.437512 -0.221852 -1.000000 -0.279301  0.036165 -0.053447 -9.354913e-03   \n",
       "28  0.506682 -0.344034 -0.566453 -0.178726  0.570518 -0.388276 -9.400190e-01   \n",
       "29  0.887790 -0.851281 -0.026287 -0.655961  0.782300 -0.713264 -1.137738e-01   \n",
       "\n",
       "          M8      M1M1      M2M2  ...          M7M4          M7M5  \\\n",
       "0  -0.404355  0.683899  0.734733  ...  6.809952e-03 -7.317699e-03   \n",
       "1  -0.108069  0.659418  0.607254  ...  6.112671e-01 -4.302778e-01   \n",
       "2  -0.165842  0.234299  0.391339  ...  2.895364e-01 -5.845359e-01   \n",
       "3  -0.502233  0.390392  0.279004  ...  1.462999e-01 -4.494863e-01   \n",
       "4  -0.316065  0.000428  0.000297  ...  3.241952e-03 -4.924603e-04   \n",
       "5  -0.053555  0.144405  0.071839  ...  5.427693e-02 -2.089382e-01   \n",
       "6  -0.151106  0.858066  0.826468  ...  1.000000e+00 -4.948777e-01   \n",
       "7  -0.461751  0.506919  0.607056  ...  3.960763e-03 -4.158547e-04   \n",
       "8  -0.569210  0.069605  0.102481  ...  2.328854e-07 -5.865410e-10   \n",
       "9  -0.241399  0.361071  0.581202  ...  1.732576e-04 -3.253978e-04   \n",
       "10 -0.533630  0.677478  0.819671  ...  2.180733e-04 -3.935125e-06   \n",
       "11 -0.129217  0.127688  0.235412  ...  1.711148e-02 -6.381956e-02   \n",
       "12 -0.209187  0.158076  0.196776  ...  4.215429e-02 -7.777720e-01   \n",
       "13 -0.169755  0.004570  0.009250  ...  1.193113e-01 -1.348994e-01   \n",
       "14 -1.000000  0.577233  0.626466  ...  2.694556e-03 -5.225240e-03   \n",
       "15 -0.009185  0.155605  0.080416  ...  8.986900e-03 -3.505941e-02   \n",
       "16 -0.727874  0.587685  0.498369  ...  8.393214e-02 -1.369860e-01   \n",
       "17 -0.487647  0.731437  0.804563  ...  1.504642e-01 -1.450646e-01   \n",
       "18 -0.097532  0.102472  0.159706  ...  4.297896e-03 -2.464569e-02   \n",
       "19 -0.066936  0.314852  0.423170  ...  7.532074e-04 -2.747374e-03   \n",
       "20 -0.055391  0.065827  0.022070  ...  1.037441e-01 -2.130153e-01   \n",
       "21 -0.070503  0.965327  0.984641  ...  1.485386e-01 -6.034361e-02   \n",
       "22 -0.701089  0.730264  0.725923  ...  7.908725e-03 -8.631805e-03   \n",
       "23 -0.655825  0.203259  0.255137  ...  2.262066e-03 -6.563362e-02   \n",
       "24 -0.222119  0.002961  0.004982  ...  1.301366e-01 -3.759101e-02   \n",
       "25 -0.513706  1.000000  1.000000  ...  2.441095e-01 -1.365292e-01   \n",
       "26 -0.088366  0.795400  0.741793  ...  5.453063e-01 -1.860421e-01   \n",
       "27 -0.480302  0.191417  0.049218  ...  7.242029e-03 -6.308457e-04   \n",
       "28 -0.256679  0.256726  0.118360  ...  4.656646e-01 -1.000000e+00   \n",
       "29 -0.405277  0.788170  0.724680  ...  2.068558e-01 -1.659623e-01   \n",
       "\n",
       "            M7M6      M8M1      M8M2      M8M3      M8M4      M8M5      M8M6  \\\n",
       "0   6.421168e-03 -0.440132  0.437903  0.018383  0.390394 -0.320333  0.312054   \n",
       "1   2.822647e-01 -0.115506  0.106399  0.004760  0.096811 -0.052037  0.037897   \n",
       "2   3.097089e-01 -0.105659  0.131076  0.151791  0.043123 -0.066479  0.039104   \n",
       "3   3.511113e-01 -0.413029  0.335168  0.206307  0.173039 -0.405961  0.352047   \n",
       "4   4.033778e-04 -0.008602  0.006882  0.000165  0.300219 -0.034823  0.031666   \n",
       "5   1.495989e-01 -0.026786  0.018136  0.029906  0.008384 -0.024644  0.019589   \n",
       "6   5.411810e-01 -0.184233  0.173559  0.001631  0.224195 -0.084721  0.102855   \n",
       "7   4.833187e-04 -0.432714  0.454541  0.097740  0.250608 -0.020092  0.025924   \n",
       "8   2.728845e-10 -0.197659  0.230221  0.082834  0.106470 -0.000205  0.000106   \n",
       "9   2.914577e-04 -0.190922  0.232515  0.287944  0.119553 -0.171456  0.170491   \n",
       "10  2.945343e-06 -0.578112  0.610395  0.169131  0.543191 -0.007485  0.006219   \n",
       "11  5.301652e-02 -0.060774  0.079211  0.096300  0.028398 -0.080876  0.074587   \n",
       "12  1.000000e+00 -0.109469  0.117239  0.020631  0.006193 -0.087256  0.124546   \n",
       "13  1.317510e-01 -0.015104  0.020628  0.006311  0.127488 -0.110069  0.119343   \n",
       "14  4.706713e-03 -1.000000  1.000000  0.049641  0.675325 -1.000000  1.000000   \n",
       "15  3.398516e-02 -0.004769  0.003291  0.005027  0.001355 -0.004037  0.004344   \n",
       "16  1.292149e-01 -0.734434  0.649207  0.115095  0.531959 -0.662970  0.694255   \n",
       "17  1.383541e-01 -0.548932  0.552633  0.041338  0.543212 -0.399913  0.423433   \n",
       "18  2.099476e-02 -0.041094  0.049245  0.028246  0.013455 -0.058915  0.055716   \n",
       "19  2.490350e-03 -0.049435  0.055013  0.024708  0.013870 -0.038632  0.038876   \n",
       "20  2.268723e-01 -0.018705  0.010397  0.028889  0.016557 -0.025960  0.030694   \n",
       "21  5.799174e-02 -0.091174  0.088389  0.000431  0.129153 -0.040065  0.042745   \n",
       "22  7.588576e-03 -0.788565  0.754692  0.000027  0.763065 -0.635953  0.620686   \n",
       "23  5.613729e-02 -0.389168  0.418530  0.089887  0.026311 -0.582949  0.553534   \n",
       "24  4.534897e-02 -0.015910  0.019808  0.002651  0.177777 -0.039213  0.052517   \n",
       "25  1.297964e-01 -0.676144  0.649031  0.000083  1.000000 -0.427080  0.450749   \n",
       "26  2.152235e-01 -0.103730  0.096157  0.003328  0.114404 -0.029804  0.038278   \n",
       "27  8.397881e-04 -0.276585  0.134626  1.000000  0.261140 -0.017370  0.025671   \n",
       "28  6.130313e-01 -0.171179  0.111569  0.302719  0.089303 -0.146440  0.099662   \n",
       "29  1.363008e-01 -0.473572  0.435889  0.022181  0.517506 -0.317048  0.289069   \n",
       "\n",
       "        M8M7  \n",
       "0   0.008302  \n",
       "1   0.214645  \n",
       "2   0.537520  \n",
       "3   0.620758  \n",
       "4   0.003140  \n",
       "5   0.054048  \n",
       "6   0.296449  \n",
       "7   0.009809  \n",
       "8   0.000002  \n",
       "9   0.000246  \n",
       "10  0.000333  \n",
       "11  0.029285  \n",
       "12  0.866979  \n",
       "13  0.078500  \n",
       "14  0.011614  \n",
       "15  0.001629  \n",
       "16  0.243317  \n",
       "17  0.191728  \n",
       "18  0.008845  \n",
       "19  0.000708  \n",
       "20  0.055960  \n",
       "21  0.016640  \n",
       "22  0.014829  \n",
       "23  0.107634  \n",
       "24  0.105125  \n",
       "25  0.187510  \n",
       "26  0.108338  \n",
       "27  0.018622  \n",
       "28  1.000000  \n",
       "29  0.191103  \n",
       "\n",
       "[30 rows x 44 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "# Подсчет макропараметров\n",
    "def macroparams(data_strat):\n",
    "   Aj = data_strat['A_J'].tolist()\n",
    "   Bj = data_strat['B_J'].tolist()\n",
    "   Aa = data_strat['A_A'].tolist()\n",
    "   Ba = data_strat['B_A'].tolist()\n",
    "   collect = defaultdict(list)\n",
    "   collect_M = defaultdict(list)\n",
    "   collect_MM = defaultdict(list)\n",
    "   for i in range(1, 9):\n",
    "      collect['M' + str(i)] = []\n",
    "   for i in range(0, Nmax):\n",
    "      collect['M1'].append(sigma1*(Aj[i] + D))\n",
    "      collect['M2'].append(-sigma2*(Aj[i] + D + Bj[i]/2))\n",
    "      collect['M3'].append(-2*(np.pi*Bj[i])**2)\n",
    "      collect['M4'].append(-((Aj[i] + D0)**2 + (Bj[i]**2)/2))\n",
    "      collect['M5'].append(sigma1*(Aa[i] + D))\n",
    "      collect['M6'].append(-sigma2*(Aa[i] + D + Ba[i]/2))\n",
    "      collect['M7'].append(-2*(np.pi*Ba[i])**2)\n",
    "      collect['M8'].append(-((Aa[i] + D0)**2 + (Ba[i]**2)/2)) \n",
    "   for i in range(1, 9):\n",
    "      for j in range(1, 9):\n",
    "         if i == j:\n",
    "            Z = np.array(collect['M' + str(i)])*np.array(collect['M' + str(j)])\n",
    "            collect_M['M' + str(i) + 'M' + str(j)].append(Z)\n",
    "         else:\n",
    "            continue\n",
    "   for i in range(2, 9):\n",
    "      for j in range(1, i):\n",
    "         Z = 2*np.array(collect['M' + str(i)])*np.array(collect['M' + str(j)])\n",
    "         collect_MM['M' + str(i) + 'M' + str(j)].append(Z)\n",
    "\n",
    "   M1, M2, M3 = macro_norm(collect, collect_M, collect_MM)\n",
    "   data_macro = {}\n",
    "   data = pd.DataFrame(data = data_macro)\n",
    "   for i in range(1, 9):\n",
    "      data['M' + str(i)] = M1['M' + str(i) + '_n'][0]\n",
    "   for i in range(1, 9):\n",
    "      for j in range(1, 9):\n",
    "         if i == j:\n",
    "            data['M' + str(i) + 'M' + str(j)] = M2['M' + str(i) + 'M' + str(j) + '_n'][0]\n",
    "         else:\n",
    "            continue\n",
    "   for i in range(2, 9):\n",
    "      for j in range(1, i):\n",
    "         data['M' + str(i) + 'M' + str(j)] = M3['M' + str(i) + 'M' + str(j) + '_n'][0]\n",
    "   data.to_csv(\"data_macro.csv\", index=False)\n",
    "   return data\n",
    "data = macroparams(data_strat)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'M' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MANDAR~1\\AppData\\Local\\Temp/ipykernel_6188/877706513.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mdata_fit_macro\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mdata_fit_macro\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MANDAR~1\\AppData\\Local\\Temp/ipykernel_6188/877706513.py\u001b[0m in \u001b[0;36mfitness\u001b[1;34m(Nmax)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m    \u001b[0mdata_macro\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmacroparams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_strat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m    \u001b[0mM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m    \u001b[0mJ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m    \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'M' is not defined"
     ]
    }
   ],
   "source": [
    "#! Придумать что-то с логистикой\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "# Считаем фитнесс\n",
    "def fitness(Nmax):\n",
    "   data_macro = macroparams(data_strat)\n",
    "   M\n",
    "   J = []\n",
    "   r, s, p, q = 0, 0, 0, 0\n",
    "   for i in range(0, Nmax):\n",
    "      r = alpha_a*M5[i] + betta_a*M7[i] + delta_a*M8[i]\n",
    "      s = gamma_a*M6['M6_n'][i]\n",
    "      p = alpha_j*M1['M1_n'][i] + betta_j*M3[i] + delta_j*M4[i]\n",
    "      q = gamma_j*M2['M2_n'][i]\n",
    "      if ((4*r*p + (p + q - s)**2) < 0):\n",
    "         J.append(0)\n",
    "      else:\n",
    "         j = -s - p - q + np.sqrt(4*r*p + (p + q - s)**2)\n",
    "         J.append(j)\n",
    "   data = pd.read_csv('data_macro.csv')\n",
    "   data.insert(0, 'J', J)\n",
    "   return data\n",
    "\n",
    "data_fit_macro = fitness(Nmax)\n",
    "data_fit_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MANDAR~1\\AppData\\Local\\Temp/ipykernel_6188/410068580.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m    \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data_fit_macro_target.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MANDAR~1\\AppData\\Local\\Temp/ipykernel_6188/410068580.py\u001b[0m in \u001b[0;36mdata_class\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdata_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m    \u001b[0mdata_fit_macro\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m    \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m    \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MANDAR~1\\AppData\\Local\\Temp/ipykernel_6188/2047307315.py\u001b[0m in \u001b[0;36mfitness\u001b[1;34m(Nmax)\u001b[0m\n\u001b[0;32m      7\u001b[0m    \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m    \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m       \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha_a\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'M5'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbetta_a\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'M7'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdelta_a\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'M8'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m       \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgamma_a\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'M6'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m       \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha_j\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'M1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbetta_j\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'M3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdelta_j\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'M4'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def classificator(differ):\n",
    "   if differ[0] < 0:\n",
    "      return -1\n",
    "   else:\n",
    "      return 1\n",
    "      \n",
    "def data_class():\n",
    "   data_fit_macro = fitness(Nmax)\n",
    "   target = []\n",
    "   for i in range(0, Nmax):\n",
    "      for j in range(i + 1, Nmax):\n",
    "         differ_ = data_fit_macro.loc[i] - data_fit_macro.loc[j]\n",
    "         target_ = classificator(differ_)\n",
    "         target.append(differ_.append(pd.Series(target_, index =['target'])))\n",
    "   data = data_fit_macro.insert('target', target)\n",
    "   data.to_csv(\"data_fit_macro_target.csv\", index=False)\n",
    "   return data\n",
    "   \n",
    "data = data_class()\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Реализация машинного обучения для SVM, LDA (от скуки написали 4 соседей (KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Разедляем данные на обучающую и тестовую выборки\n",
    "X = data.iloc[:, 1:-1].values \n",
    "y = data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7317485973187687,\n",
       " 0.6651481597809845,\n",
       " 0.8533868699075384,\n",
       " 1.1588143115248315,\n",
       " 2.9374985907340525,\n",
       " -4.558035574111023,\n",
       " -0.12820786540167373,\n",
       " 0.6264659210798238]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Реализуем SVM\n",
    "from sklearn.svm import SVC\n",
    "SVC_model = SVC(kernel= 'linear')\n",
    "SVC_model.fit(X_train, y_train)\n",
    "SVC_prediction = SVC_model.predict(X_test)\n",
    "\n",
    "# Получим коэффициенты гиперплоскости\n",
    "SVC_coef = SVC_model.coef_.tolist()\n",
    "SVC_coef = SVC_coef[0]\n",
    "SVC_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.8401303420310704,\n",
       " -1.249342882452703,\n",
       " -0.33737824016591167,\n",
       " 1.9021688514028035,\n",
       " -0.391022607811524,\n",
       " -13.805609795250039,\n",
       " 0.09585172172578166,\n",
       " -1.7963252892393515]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Реализуем LDA\n",
    "from sklearn import discriminant_analysis\n",
    "LDA_model = discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "LDA_model.fit(X_train, y_train)\n",
    "LDA_prediction = LDA_model.predict(X_test)\n",
    "\n",
    "# Получим коэффициенты гиперплоскости\n",
    "LDA_coef = LDA_model.coef_.tolist()\n",
    "LDA_coef = LDA_coef[0]\n",
    "LDA_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуем KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN_model = KNeighborsClassifier(n_neighbors=4)\n",
    "KNN_model.fit(X_train, y_train)\n",
    "KNN_prediction = KNN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность классификатора:\n",
      "     SVM:  0.9310344827586207\n",
      "     LDA:  0.9770114942528736\n",
      "     KNN:  0.8505747126436781   (Сделали от скуки)\n",
      "Логарифмическая потеря:\n",
      "     SVM:  0.9471264367816092\n",
      "     LDA:  0.9494252873563218\n"
     ]
    }
   ],
   "source": [
    "# Считаем разницу SVM и LDA (KNN)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import model_selection\n",
    "print('Точность классификатора:')\n",
    "print('     SVM: ', accuracy_score(SVC_prediction, y_test))\n",
    "print('     LDA: ', accuracy_score(LDA_prediction, y_test))\n",
    "print('     KNN: ', accuracy_score(KNN_prediction, y_test), '  (Сделали от скуки)')\n",
    "\n",
    "SVM = model_selection.cross_val_score(SVC_model, X, y)\n",
    "LDA = model_selection.cross_val_score(LDA_model, X, y)\n",
    "print('Логарифмическая потеря:')\n",
    "print('     SVM: ', SVM.mean())\n",
    "print('     LDA: ', LDA.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Графики "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Двумерные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" import matplotlib.pyplot as plt\\nX=data_class().loc[:,'M1':'M8']\\ny=data_class().loc[:,'target']\\nX1 = X[y==1]\\nX0 = X[y==-1]\\nfor i in range(len(X.columns)):\\n    for j in range(i + 1, len(X.columns)):\\n        x=np.linspace(-1, 1)\\n        plt.figure(figsize=(7, 7))\\n        plt.scatter(x = X1[X.columns[i]], y=X1[X.columns[j]], marker='.')\\n        plt.scatter(x = X0[X.columns[i]], y=X0[X.columns[j]], marker='x')\\n        plt.plot(x, (-1)* SVC_coef[i] / SVC_coef[j] * x, label='SVM')\\n        plt.plot(x, (-1)* LDA_coef[i] / LDA_coef[j] * x, label='LDA')\\n        plt.xlim(-1,)\\n        plt.ylim(-1,1)\\n        plt.legend()\\n        plt.xlabel(X.columns[i])\\n        plt.ylabel(X.columns[j])\\n        plt.grid()\\n        plt.show() \""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import matplotlib.pyplot as plt\n",
    "X=data_class().loc[:,'M1':'M8']\n",
    "y=data_class().loc[:,'target']\n",
    "X1 = X[y==1]\n",
    "X0 = X[y==-1]\n",
    "for i in range(len(X.columns)):\n",
    "    for j in range(i + 1, len(X.columns)):\n",
    "        x=np.linspace(-1, 1)\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        plt.scatter(x = X1[X.columns[i]], y=X1[X.columns[j]], marker='.')\n",
    "        plt.scatter(x = X0[X.columns[i]], y=X0[X.columns[j]], marker='x')\n",
    "        plt.plot(x, (-1)* SVC_coef[i] / SVC_coef[j] * x, label='SVM')\n",
    "        plt.plot(x, (-1)* LDA_coef[i] / LDA_coef[j] * x, label='LDA')\n",
    "        plt.xlim(-1,)\n",
    "        plt.ylim(-1,1)\n",
    "        plt.legend()\n",
    "        plt.xlabel(X.columns[i])\n",
    "        plt.ylabel(X.columns[j])\n",
    "        plt.grid()\n",
    "        plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Трехмерные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" import matplotlib.pyplot as plt\\nX=data_class().loc[:,'M1':'M8']\\ny=data_class().loc[:,'target']\\nX1 = X[y==1]\\nX0 = X[y==-1]\\nfor i in range(len(X.columns)):\\n    for j in range(len(X.columns)):\\n        for k in range(len(X.columns)):\\n            if i == j or j == k or i == k:\\n                continue\\n            u, v = np.mgrid[-1:1:20j, -1:1:20j]\\n            fig = plt.figure(figsize=(10, 10))\\n            ax = fig.add_subplot(111, projection='3d')\\n            ax.scatter(X1[X.columns[i]], X1[X.columns[j]], X1[X.columns[k]], marker='.')\\n            ax.scatter(X0[X.columns[i]], X0[X.columns[j]], X0[X.columns[k]], marker='x')\\n            ax.plot_surface(u , v, (-1)* (SVC_coef[i] * u + SVC_coef[j] * v) / SVC_coef[k], alpha=0.666, color='orange')\\n            ax.set_xlabel(X.columns[i])\\n            ax.set_ylabel(X.columns[j])\\n            ax.set_zlabel(X.columns[k])\\n            plt.legend()\\n            plt.grid()\\n            plt.show() \""
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import matplotlib.pyplot as plt\n",
    "X=data_class().loc[:,'M1':'M8']\n",
    "y=data_class().loc[:,'target']\n",
    "X1 = X[y==1]\n",
    "X0 = X[y==-1]\n",
    "for i in range(len(X.columns)):\n",
    "    for j in range(len(X.columns)):\n",
    "        for k in range(len(X.columns)):\n",
    "            if i == j or j == k or i == k:\n",
    "                continue\n",
    "            u, v = np.mgrid[-1:1:20j, -1:1:20j]\n",
    "            fig = plt.figure(figsize=(10, 10))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            ax.scatter(X1[X.columns[i]], X1[X.columns[j]], X1[X.columns[k]], marker='.')\n",
    "            ax.scatter(X0[X.columns[i]], X0[X.columns[j]], X0[X.columns[k]], marker='x')\n",
    "            ax.plot_surface(u , v, (-1)* (SVC_coef[i] * u + SVC_coef[j] * v) / SVC_coef[k], alpha=0.666, color='orange')\n",
    "            ax.set_xlabel(X.columns[i])\n",
    "            ax.set_ylabel(X.columns[j])\n",
    "            ax.set_zlabel(X.columns[k])\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Этап 2 | Построение фитнеса | Поиск оптимальной траектории | Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" import random as rn\\nimport numpy as np\\nfrom scipy.optimize import differential_evolution\\n\\n\\ndef F(A):\\n   return (SVC_coef[0]*sigma1 - 2*SVC_coef[3]*(A + D0))/(2*(4*(np.pi**2)*SVC_coef[2] + SVC_coef[3]))\\n\\nA = np.array(data_strat['A_J'].tolist())\\n\\n\\n\\nabc = differential_evolution(F, bounds=(-D, 0))\\nabc\\n\\n \""
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import random as rn\n",
    "import numpy as np\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "\n",
    "def F(A):\n",
    "   return (SVC_coef[0]*sigma1 - 2*SVC_coef[3]*(A + D0))/(2*(4*(np.pi**2)*SVC_coef[2] + SVC_coef[3]))\n",
    "\n",
    "A = np.array(data_strat['A_J'].tolist())\n",
    "\n",
    "\n",
    "\n",
    "abc = differential_evolution(F, bounds=(-D, 0))\n",
    "abc\n",
    "\n",
    " \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x162da5f9790>]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t = np.linspace(0, 1, 20)\n",
    "xj = -14.9593 + 1.84831899*np.cos(2*np.pi*t)\n",
    "xa = -54.9131 - 33.27123058*np.cos(2*np.pi*t)\n",
    "\n",
    "plt.plot(t, xj)\n",
    "plt.plot(t, xa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b333a8d4eeb79150063cd478df1127258f76b9566e6feb3a67bc081e7bfcc4e6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
